{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Playoff Predictor - Data Cleaning\n",
    "\n",
    "This notebook focuses on cleaning and preprocessing the raw NBA data from Kaggle sources. We'll prepare the data for feature engineering by standardizing formats, handling missing values, and ensuring data quality across different sources.\n",
    "\n",
    "## Data Sources and Cleaning Goals\n",
    "\n",
    "1. NBA/ABA/BAA Stats (sumitrodatta)\n",
    "   - Player Season Info: Contains individual player statistics per season\n",
    "     - Cleaning focuses on standardizing team names, filtering for NBA-only data, and handling missing values\n",
    "   - Team Stats Per Game: Contains team-level performance metrics\n",
    "     - Cleaning involves normalizing team names and ensuring consistent statistical calculations\n",
    "\n",
    "2. NBA Injury Stats (loganlauton)\n",
    "   - Contains historical injury data from 1951-2023\n",
    "   - Cleaning involves:\n",
    "     - Standardizing injury descriptions\n",
    "     - Converting dates to consistent format\n",
    "     - Matching team names with other datasets\n",
    "     - Removing duplicate entries\n",
    "\n",
    "3. NBA Shots Data (mexwell)\n",
    "   - Contains detailed shot location and outcome data\n",
    "   - Cleaning involves:\n",
    "     - Standardizing coordinate systems\n",
    "     - Validating shot types and distances\n",
    "     - Ensuring consistent player and team naming\n",
    "     - Removing invalid or incomplete shot records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.cleaners.base_cleaner import BaseNBACleaner\n",
    "\n",
    "from src.data.cleaners.loganlauton_cleaner import LoganlautonCleaner\n",
    "from src.data.cleaners.mexwell_cleaner import MexwellCleaner\n",
    "from src.data.utils import setup_logging\n",
    "\n",
    "logger = setup_logging()\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean NBA/ABA/BBA Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean NBA/ABA/BAA Stats\n",
    "\n",
    "Process data from sumitrodatta's dataset.\n",
    "\n",
    "The cleaning process ensures consistent formatting and removes any anomalies that could affect our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Season Data Cleaning Script\n",
    "\n",
    "This script is designed to clean and standardize NBA player season data for analysis. It performs the following operations:\n",
    "\n",
    "1. **Load Data**: Reads the raw player season data from a CSV file.\n",
    "2. **Filter by Season**: Removes records from seasons prior to 2004 to focus on recent data.\n",
    "3. **Drop Unnecessary Columns**: Eliminates irrelevant columns such as `player_id`, `seas_id`, `birth_year`, `pos`, and `lg` to streamline the dataset.\n",
    "4. **Standardize Names**:\n",
    "   - Player names are standardized using `BaseNBACleaner` for consistency.\n",
    "   - Team names are converted to uppercase, stripped of whitespace, and renamed from `tm` to `team` for clarity.\n",
    "5. **Convert Columns**:\n",
    "   - The `age` column is converted to an integer type to ensure proper numeric handling.\n",
    "   - (Optional) Other numeric columns can be standardized if required.\n",
    "6. **Validate Data**:\n",
    "   - Checks for missing values (`NaN`) in all columns and logs detailed information for debugging.\n",
    "7. **Save Cleaned Data**: Exports the cleaned dataset to a new CSV file for further analysis.\n",
    "\n",
    "### Output\n",
    "- A cleaned dataset is saved as `../data/processed/historical/player_season.csv`.\n",
    "- Logs provide detailed information about the cleaning process, including record counts, transformations, and validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 23:28:18 - INFO - Loading player season info data...\n",
      "2024-12-10 23:28:18 - INFO - Initial player season info records: 32,358\n",
      "2024-12-10 23:28:18 - INFO - Filtering out records before 2004...\n",
      "2024-12-10 23:28:18 - INFO - Records after filtering pre-2004 data: 13,629\n",
      "2024-12-10 23:28:18 - INFO - Dropping unnecessary columns: ['player_id', 'seas_id', 'birth_year', 'pos', 'lg']...\n",
      "2024-12-10 23:28:18 - INFO - Unnecessary columns dropped.\n",
      "2024-12-10 23:28:18 - INFO - Standardizing player names...\n",
      "2024-12-10 23:28:18 - INFO - Player name standardization complete.\n",
      "2024-12-10 23:28:18 - INFO - Standardizing team names: converting to uppercase and stripping whitespace...\n",
      "2024-12-10 23:28:18 - INFO - Team name standardization complete.\n",
      "2024-12-10 23:28:18 - INFO - Renaming 'tm' column to 'team'...\n",
      "2024-12-10 23:28:18 - INFO - Column 'tm' successfully renamed to 'team'.\n",
      "2024-12-10 23:28:18 - INFO - Converting 'age' column to integer type...\n",
      "2024-12-10 23:28:18 - INFO - 'age' column conversion to integer complete.\n",
      "2024-12-10 23:28:18 - INFO - Converting numeric columns to appropriate data types...\n",
      "2024-12-10 23:28:18 - INFO - Numeric column conversion complete.\n",
      "2024-12-10 23:28:18 - INFO - Final cleaned player season info records: 13,629\n",
      "2024-12-10 23:28:18 - INFO - Checking for NaN values in the dataset...\n",
      "2024-12-10 23:28:18 - INFO - No NaN values found in the cleaned DataFrame.\n",
      "2024-12-10 23:28:18 - INFO - Displaying the first 10 rows of the cleaned DataFrame...\n",
      "2024-12-10 23:28:18 - INFO - Saving cleaned data to ../data/processed/historical/player_season.csv...\n",
      "2024-12-10 23:28:18 - INFO - Cleaned data successfully saved to ../data/processed/historical/player_season.csv.\n",
      "2024-12-10 23:28:18 - INFO - Displaying column names in the cleaned DataFrame...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       season           player  age team  experience\n",
      "18729    2004      Aaron McKie   31  PHI          10\n",
      "18730    2004   Aaron Williams   32  NJN          10\n",
      "18731    2004     Adonal Foyle   28  GSW           7\n",
      "18732    2004   Adrian Griffin   29  HOU           5\n",
      "18733    2004    Al Harrington   23  IND           6\n",
      "18734    2004   Alan Henderson   31  ATL           9\n",
      "18735    2004      Alex Garcia   23  SAS           1\n",
      "18736    2004    Allan Houston   32  NYK          11\n",
      "18737    2004    Allen Iverson   28  PHI           8\n",
      "18738    2004  Alonzo Mourning   33  NJN          11\n",
      "['season', 'player', 'age', 'team', 'experience']\n"
     ]
    }
   ],
   "source": [
    "cleaner = BaseNBACleaner()\n",
    "\n",
    "# Load and clean player season info data\n",
    "logger.info(\"Loading player season info data...\")\n",
    "ps_df_raw = pd.read_csv('../data/raw/kaggle/sumitrodatta/nba-aba-baa-stats/Player Season Info.csv')\n",
    "logger.info(f\"Initial player season info records: {len(ps_df_raw):,}\")\n",
    "\n",
    "# Make a copy of the raw data for processing\n",
    "ps_df_processed = ps_df_raw.copy()\n",
    "\n",
    "# Filter out data before 2004\n",
    "logger.info(\"Filtering out records before 2004...\")\n",
    "ps_df_processed = ps_df_processed[ps_df_processed['season'] >= 2004]\n",
    "logger.info(f\"Records after filtering pre-2004 data: {len(ps_df_processed):,}\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['player_id', 'seas_id', 'birth_year', 'pos', 'lg']\n",
    "logger.info(f\"Dropping unnecessary columns: {columns_to_drop}...\")\n",
    "ps_df_processed.drop(columns=columns_to_drop, inplace=True)\n",
    "logger.info(\"Unnecessary columns dropped.\")\n",
    "\n",
    "# Standardize player names\n",
    "logger.info(\"Standardizing player names...\")\n",
    "ps_df_processed = cleaner.standardize_player_names(ps_df_processed)\n",
    "logger.info(\"Player name standardization complete.\")\n",
    "\n",
    "# Standardize team names\n",
    "logger.info(\"Standardizing team names: converting to uppercase and stripping whitespace...\")\n",
    "ps_df_processed['tm'] = ps_df_processed['tm'].str.strip().str.upper()\n",
    "ps_df_processed = cleaner.standardize_team_names(ps_df_processed, ['tm'])\n",
    "logger.info(\"Team name standardization complete.\")\n",
    "\n",
    "# Rename 'tm' column to 'team'\n",
    "logger.info(\"Renaming 'tm' column to 'team'...\")\n",
    "ps_df_processed.rename(columns={'tm': 'team'}, inplace=True)\n",
    "logger.info(\"Column 'tm' successfully renamed to 'team'.\")\n",
    "\n",
    "# Convert 'age' column to integer type\n",
    "logger.info(\"Converting 'age' column to integer type...\")\n",
    "ps_df_processed['age'] = pd.to_numeric(ps_df_processed['age'], errors='coerce').fillna(0).astype(int)\n",
    "logger.info(\"'age' column conversion to integer complete.\")\n",
    "\n",
    "# Convert numeric columns to appropriate types\n",
    "logger.info(\"Converting numeric columns to appropriate data types...\")\n",
    "# Uncomment the next line if numeric column handling is necessary\n",
    "# ps_df_processed = cleaner.handle_numeric_columns(ps_df_processed)\n",
    "logger.info(\"Numeric column conversion complete.\")\n",
    "\n",
    "# Log final record count\n",
    "logger.info(f\"Final cleaned player season info records: {len(ps_df_processed):,}\")\n",
    "\n",
    "# Check for NaN values in any column\n",
    "logger.info(\"Checking for NaN values in the dataset...\")\n",
    "nan_cols = ps_df_processed.columns[ps_df_processed.isna().any()].tolist()\n",
    "if nan_cols:\n",
    "    logger.warning(f\"Found NaN values in the following columns: {nan_cols}\")\n",
    "    for col in nan_cols:\n",
    "        nan_count = ps_df_processed[col].isna().sum()\n",
    "        logger.warning(f\"Column '{col}' has {nan_count:,} NaN values.\")\n",
    "else:\n",
    "    logger.info(\"No NaN values found in the cleaned DataFrame.\")\n",
    "\n",
    "# Display the first 10 rows for validation\n",
    "logger.info(\"Displaying the first 10 rows of the cleaned DataFrame...\")\n",
    "print(ps_df_processed.head(10))\n",
    "\n",
    "# Save the cleaned data to a CSV file\n",
    "output_path = '../data/processed/historical/player_season.csv'\n",
    "logger.info(f\"Saving cleaned data to {output_path}...\")\n",
    "ps_df_processed.to_csv(output_path, index=False)\n",
    "logger.info(f\"Cleaned data successfully saved to {output_path}.\")\n",
    "\n",
    "# Display the final column names\n",
    "logger.info(\"Displaying column names in the cleaned DataFrame...\")\n",
    "print(ps_df_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Statistics Data Cleaning Script\n",
    "\n",
    "This script processes and cleans NBA team statistics data for analysis. It performs the following steps:\n",
    "\n",
    "1. **Load Data**: Reads the raw team statistics data from a CSV file.\n",
    "2. **Filter by Season**: Removes records for seasons prior to 2004, focusing on modern basketball data.\n",
    "3. **Remove League Averages**: Excludes entries labeled as \"League Average\" to ensure team-specific analysis.\n",
    "4. **Standardize Team Names**:\n",
    "   - Converts team names to uppercase.\n",
    "   - Strips unnecessary whitespace.\n",
    "   - Uses `BaseNBACleaner` to map team names to standardized three-letter codes.\n",
    "5. **Convert Columns**:\n",
    "   - Converts numeric columns to the appropriate data types.\n",
    "   - Transforms percentage values (e.g., \"45.6%\") into decimal form (e.g., `0.456`) for easier calculations.\n",
    "6. **Validate Data**:\n",
    "   - Checks for missing values (`NaN`) in all columns and logs detailed warnings for any issues.\n",
    "7. **Save Cleaned Data**: Exports the cleaned dataset to a CSV file for further analysis or modeling.\n",
    "\n",
    "### Output\n",
    "- The cleaned dataset is saved as `../data/processed/historical/team_stats.csv`.\n",
    "- Detailed logs capture every step of the cleaning process, including record counts, transformations, and validation results.\n",
    "\n",
    "### Benefits\n",
    "- Ensures consistent formatting and structure across all team data.\n",
    "- Prepares the data for advanced analytics by eliminating non-relevant entries and handling numeric conversions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 23:29:26 - INFO - Loading team stats data...\n",
      "2024-12-10 23:29:26 - INFO - Initial team stats records: 1,876\n",
      "2024-12-10 23:29:26 - INFO - Filtering out records before 2004...\n",
      "2024-12-10 23:29:26 - INFO - Records after filtering pre-2004 data: 681\n",
      "2024-12-10 23:29:26 - INFO - Removing 'League Average' entries from the data...\n",
      "2024-12-10 23:29:26 - INFO - Records after removing 'League Average' entries: 659\n",
      "2024-12-10 23:29:26 - INFO - Standardizing team names: converting to uppercase and stripping whitespace...\n",
      "2024-12-10 23:29:26 - INFO - Team name standardization complete.\n",
      "2024-12-10 23:29:26 - INFO - Converting numeric columns to appropriate data types...\n",
      "2024-12-10 23:29:26 - INFO - Numeric column conversion complete.\n",
      "2024-12-10 23:29:26 - INFO - Converting percentage strings to decimal values...\n",
      "2024-12-10 23:29:26 - INFO - Percentage conversion complete.\n",
      "2024-12-10 23:29:26 - INFO - Final cleaned team statistics records: 659\n",
      "2024-12-10 23:29:26 - INFO - Checking for NaN values in the dataset...\n",
      "2024-12-10 23:29:26 - INFO - No NaN values found in the cleaned DataFrame.\n",
      "2024-12-10 23:29:26 - INFO - Displaying the first 10 rows of the cleaned DataFrame...\n",
      "2024-12-10 23:29:26 - INFO - Saving cleaned data to ../data/processed/historical/team_stats.csv...\n",
      "2024-12-10 23:29:26 - INFO - Cleaned data successfully saved to ../data/processed/historical/team_stats.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season   lg team abbreviation  playoffs     g  mp_per_game  fg_per_game  \\\n",
      "0    2025  NBA  ATL          ATL     False  21.0        240.0         42.4   \n",
      "1    2025  NBA  BOS          BOS     False  19.0        243.9         41.8   \n",
      "2    2025  NBA  BKN          BRK     False  20.0        242.5         39.4   \n",
      "3    2025  NBA  CHI          CHI     False  21.0        240.0         43.1   \n",
      "4    2025  NBA  CHA          CHO     False  20.0        242.5         38.6   \n",
      "5    2025  NBA  CLE          CLE     False  20.0        240.0         45.6   \n",
      "6    2025  NBA  DAL          DAL     False  20.0        241.3         43.7   \n",
      "7    2025  NBA  DEN          DEN     False  17.0        242.9         42.9   \n",
      "8    2025  NBA  DET          DET     False  22.0        243.4         40.4   \n",
      "9    2025  NBA  GSW          GSW     False  19.0        241.3         42.5   \n",
      "\n",
      "   fga_per_game  fg_percent  ...  ft_percent  orb_per_game  drb_per_game  \\\n",
      "0          91.5       0.463  ...       0.783          12.3          32.9   \n",
      "1          90.3       0.464  ...       0.806          10.1          33.2   \n",
      "2          84.0       0.468  ...       0.808           8.5          29.8   \n",
      "3          90.8       0.475  ...       0.789           8.9          35.2   \n",
      "4          91.0       0.424  ...       0.783          13.4          32.4   \n",
      "5          89.2       0.511  ...       0.788           9.3          33.7   \n",
      "6          90.6       0.483  ...       0.774          11.6          34.0   \n",
      "7          89.5       0.480  ...       0.769          11.8          33.1   \n",
      "8          88.0       0.459  ...       0.763          11.5          34.7   \n",
      "9          92.9       0.457  ...       0.702          13.4          35.6   \n",
      "\n",
      "   trb_per_game  ast_per_game  stl_per_game  blk_per_game  tov_per_game  \\\n",
      "0          45.2          29.8           9.9           5.6          16.4   \n",
      "1          43.3          25.9           7.3           5.3          11.6   \n",
      "2          38.3          26.4           6.4           3.7          14.6   \n",
      "3          44.1          28.7           7.0           4.6          15.4   \n",
      "4          45.8          22.9           8.1           5.2          16.2   \n",
      "5          42.9          28.2           9.3           4.9          13.1   \n",
      "6          45.6          25.6           8.0           5.4          13.4   \n",
      "7          44.8          29.9           8.6           4.8          14.1   \n",
      "8          46.2          25.3           5.9           5.5          16.4   \n",
      "9          49.0          29.9           9.1           5.5          14.3   \n",
      "\n",
      "   pf_per_game  pts_per_game  \n",
      "0         18.8         116.1  \n",
      "1         16.6         121.2  \n",
      "2         22.3         111.8  \n",
      "3         18.4         118.5  \n",
      "4         21.3         107.5  \n",
      "5         18.5         122.4  \n",
      "6         20.9         117.0  \n",
      "7         18.6         117.8  \n",
      "8         20.0         109.8  \n",
      "9         21.2         116.2  \n",
      "\n",
      "[10 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "cleaner = BaseNBACleaner()\n",
    "\n",
    "# Load and clean team stats data\n",
    "logger.info(\"Loading team stats data...\")\n",
    "ts_df_raw = pd.read_csv('../data/raw/kaggle/sumitrodatta/nba-aba-baa-stats/Team Stats Per Game.csv')\n",
    "logger.info(f\"Initial team stats records: {len(ts_df_raw):,}\")\n",
    "\n",
    "# Make a copy of the raw data for processing\n",
    "ts_df_processed = ts_df_raw.copy()\n",
    "\n",
    "# Filter out data before 2004\n",
    "logger.info(\"Filtering out records before 2004...\")\n",
    "ts_df_processed = ts_df_processed[ts_df_processed['season'] >= 2004]\n",
    "logger.info(f\"Records after filtering pre-2004 data: {len(ts_df_processed):,}\")\n",
    "\n",
    "# Remove League Average entries\n",
    "logger.info(\"Removing 'League Average' entries from the data...\")\n",
    "ts_df_processed = ts_df_processed[~ts_df_processed['team'].str.contains('League Average', case=False, na=False)]\n",
    "logger.info(f\"Records after removing 'League Average' entries: {len(ts_df_processed):,}\")\n",
    "\n",
    "# Standardize team names\n",
    "logger.info(\"Standardizing team names: converting to uppercase and stripping whitespace...\")\n",
    "ts_df_processed['team'] = ts_df_processed['team'].str.strip().str.upper()\n",
    "ts_df_processed = cleaner.standardize_team_names(ts_df_processed, ['team'])\n",
    "logger.info(\"Team name standardization complete.\")\n",
    "\n",
    "# Convert numeric columns to appropriate types\n",
    "logger.info(\"Converting numeric columns to appropriate data types...\")\n",
    "# Uncomment the line below if numeric column handling is needed\n",
    "# ts_df_processed = cleaner.handle_numeric_columns(ts_df_processed)\n",
    "logger.info(\"Numeric column conversion complete.\")\n",
    "\n",
    "# Convert percentage strings to decimals\n",
    "logger.info(\"Converting percentage strings to decimal values...\")\n",
    "ts_df_processed = cleaner.convert_percentages(ts_df_processed)\n",
    "logger.info(\"Percentage conversion complete.\")\n",
    "\n",
    "# Log final record count\n",
    "logger.info(f\"Final cleaned team statistics records: {len(ts_df_processed):,}\")\n",
    "\n",
    "# Check for NaN values in any column\n",
    "logger.info(\"Checking for NaN values in the dataset...\")\n",
    "nan_cols = ts_df_processed.columns[ts_df_processed.isna().any()].tolist()\n",
    "if nan_cols:\n",
    "    logger.warning(f\"Found NaN values in the following columns: {nan_cols}\")\n",
    "    for col in nan_cols:\n",
    "        nan_count = ts_df_processed[col].isna().sum()\n",
    "        logger.warning(f\"Column '{col}' has {nan_count:,} NaN values.\")\n",
    "else:\n",
    "    logger.info(\"No NaN values found in the cleaned DataFrame.\")\n",
    "\n",
    "# Display the first 10 rows for validation\n",
    "logger.info(\"Displaying the first 10 rows of the cleaned DataFrame...\")\n",
    "print(ts_df_processed.head(10))\n",
    "\n",
    "# Save the cleaned data to a CSV file\n",
    "output_path = '../data/processed/historical/team_stats.csv'\n",
    "logger.info(f\"Saving cleaned data to {output_path}...\")\n",
    "ts_df_processed.to_csv(output_path, index=False)\n",
    "logger.info(f\"Cleaned data successfully saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injury Data Cleaning and Summary Script\n",
    "\n",
    "This script processes NBA player injury data to clean and standardize it while summarizing the number of injuries per team per season. Additionally, it ensures consistency in column naming conventions by converting column names to lowercase.\n",
    "\n",
    "## Key Steps:\n",
    "\n",
    "1. **Load Data**:\n",
    "   - Reads raw injury data from a CSV file.\n",
    "   - Logs the initial number of records for traceability.\n",
    "\n",
    "2. **Data Cleaning**:\n",
    "   - Converts `Date` to a datetime format for proper filtering and analysis.\n",
    "   - Filters out records before 2004 to focus on modern data.\n",
    "   - Drops unnecessary columns: `['Unnamed: 0', 'Acquired', 'Relinquished', 'Notes']`.\n",
    "\n",
    "3. **Team Name Standardization**:\n",
    "   - Strips whitespace and converts team names to uppercase.\n",
    "   - Maps team names to standardized three-letter codes using `BaseNBACleaner`.\n",
    "\n",
    "4. **Validation**:\n",
    "   - Checks for missing values (`NaN`) in all columns.\n",
    "   - Logs details of any missing data for debugging.\n",
    "\n",
    "5. **Injury Summary**:\n",
    "   - Extracts the `Year` from the `Date` column for grouping.\n",
    "   - Groups the data by `Year` and `Team` and counts the number of injuries for each combination.\n",
    "\n",
    "6. **Column Name Standardization**:\n",
    "   - Converts all column names to lowercase for consistency and ease of integration with other processes.\n",
    "\n",
    "7. **Save Processed Data**:\n",
    "   - Exports the cleaned data and the summarized injury counts to separate CSV files:\n",
    "     - Cleaned data: `../data/processed/historical/injuries.csv`\n",
    "     - Injury summary: `../data/processed/historical/injury_summary.csv`\n",
    "\n",
    "8. **Validation Outputs**:\n",
    "   - Displays the first 10 rows of both the cleaned data and the summary data for validation.\n",
    "\n",
    "## Outputs:\n",
    "\n",
    "### Cleaned Data (Lowercase Column Names):\n",
    "Example of cleaned data:\n",
    "```plaintext\n",
    "          date     team\n",
    "6282 2004-01-02      MIA\n",
    "6283 2004-01-02      MIA\n",
    "6284 2004-01-02      DAL\n",
    "6285 2004-01-02      GSW\n",
    "6286 2004-01-04      LAL\n",
    "6287 2004-01-04      LAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 23:30:42 - INFO - Loading player injury data...\n",
      "2024-12-10 23:30:42 - INFO - Initial player injury records: 37,667\n",
      "2024-12-10 23:30:42 - INFO - Converting 'Date' column to datetime format...\n",
      "2024-12-10 23:30:42 - INFO - Date conversion complete.\n",
      "2024-12-10 23:30:42 - INFO - Filtering out records before 2004...\n",
      "2024-12-10 23:30:42 - INFO - Records after filtering pre-2004 data: 31,385\n",
      "2024-12-10 23:30:42 - INFO - Dropping unnecessary columns: ['Unnamed: 0', 'Acquired', 'Relinquished', 'Notes']...\n",
      "2024-12-10 23:30:42 - INFO - Unnecessary columns dropped.\n",
      "2024-12-10 23:30:42 - INFO - Standardizing team names: converting to uppercase, stripping whitespace, and mapping to three-letter codes...\n",
      "2024-12-10 23:30:42 - INFO - Team name standardization complete.\n",
      "2024-12-10 23:30:42 - INFO - Final cleaned player injury records: 31,385\n",
      "2024-12-10 23:30:42 - INFO - Checking for NaN values in the dataset...\n",
      "2024-12-10 23:30:42 - INFO - No NaN values found in the cleaned DataFrame.\n",
      "2024-12-10 23:30:42 - INFO - Displaying the first 10 rows of the cleaned DataFrame...\n",
      "2024-12-10 23:30:42 - INFO - Extracting 'Year' from the 'Date' column...\n",
      "2024-12-10 23:30:42 - INFO - 'Year' extraction complete.\n",
      "2024-12-10 23:30:42 - INFO - Grouping data by 'Year' and 'Team' and counting occurrences...\n",
      "2024-12-10 23:30:42 - INFO - Converting summary DataFrame column names to lowercase...\n",
      "2024-12-10 23:30:42 - INFO - Column name conversion complete.\n",
      "2024-12-10 23:30:42 - INFO - Displaying the first 10 rows of the grouped injury summary...\n",
      "2024-12-10 23:30:42 - INFO - Saving cleaned injury data to ../data/processed/historical/injury_data_processed.csv...\n",
      "2024-12-10 23:30:42 - INFO - Cleaned injury data successfully saved to ../data/processed/historical/injury_data_processed.csv.\n",
      "2024-12-10 23:30:42 - INFO - Saving summarized injury data to ../data/processed/historical/injuries_summary.csv...\n",
      "2024-12-10 23:30:42 - INFO - Summarized injury data successfully saved to ../data/processed/historical/injuries_summary.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date     Team\n",
      "6282 2004-01-02      MIA\n",
      "6283 2004-01-02      MIA\n",
      "6284 2004-01-02      DAL\n",
      "6285 2004-01-02      GSW\n",
      "6286 2004-01-04      LAL\n",
      "6287 2004-01-04      LAL\n",
      "6288 2004-01-05  BLAZERS\n",
      "6289 2004-01-05      UTA\n",
      "6290 2004-01-05      SAS\n",
      "6291 2004-01-05      SAS\n",
      "   year     team  count\n",
      "0  2004      ATL     20\n",
      "1  2004      BKN     21\n",
      "2  2004  BLAZERS     16\n",
      "3  2004  BOBCATS     15\n",
      "4  2004      BOS     16\n",
      "5  2004      CHA     21\n",
      "6  2004      CHI     25\n",
      "7  2004      CLE     41\n",
      "8  2004      DAL     17\n",
      "9  2004      DEN     22\n"
     ]
    }
   ],
   "source": [
    "cleaner = BaseNBACleaner()\n",
    "\n",
    "# Load and preserve original injury data\n",
    "logger.info(\"Loading player injury data...\")\n",
    "injury_df_raw = pd.read_csv('../data/raw/kaggle/loganlauton/nba-injury-stats-1951-2023/NBA Player Injury Stats(1951 - 2023).csv')\n",
    "logger.info(f\"Initial player injury records: {len(injury_df_raw):,}\")\n",
    "\n",
    "# Make a copy of the raw data for processing\n",
    "injury_df_processed = injury_df_raw.copy()\n",
    "\n",
    "# Convert dates to datetime\n",
    "logger.info(\"Converting 'Date' column to datetime format...\")\n",
    "injury_df_processed = cleaner.handle_dates(injury_df_processed, ['Date'])\n",
    "logger.info(\"Date conversion complete.\")\n",
    "\n",
    "# Filter out data before 2004\n",
    "logger.info(\"Filtering out records before 2004...\")\n",
    "injury_df_processed = injury_df_processed[injury_df_processed['Date'] >= '2004-01-01']\n",
    "logger.info(f\"Records after filtering pre-2004 data: {len(injury_df_processed):,}\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['Unnamed: 0', 'Acquired', 'Relinquished', 'Notes']\n",
    "logger.info(f\"Dropping unnecessary columns: {columns_to_drop}...\")\n",
    "injury_df_processed.drop(columns=columns_to_drop, inplace=True)\n",
    "logger.info(\"Unnecessary columns dropped.\")\n",
    "\n",
    "# Standardize team names\n",
    "logger.info(\"Standardizing team names: converting to uppercase, stripping whitespace, and mapping to three-letter codes...\")\n",
    "injury_df_processed['Team'] = injury_df_processed['Team'].str.strip().str.upper()\n",
    "injury_df_processed = cleaner.standardize_team_names(injury_df_processed, ['Team'])\n",
    "logger.info(\"Team name standardization complete.\")\n",
    "\n",
    "# Log final record count\n",
    "logger.info(f\"Final cleaned player injury records: {len(injury_df_processed):,}\")\n",
    "\n",
    "# Check for NaN values in any column\n",
    "logger.info(\"Checking for NaN values in the dataset...\")\n",
    "nan_cols = injury_df_processed.columns[injury_df_processed.isna().any()].tolist()\n",
    "if nan_cols:\n",
    "    logger.warning(f\"Found NaN values in the following columns: {nan_cols}\")\n",
    "    for col in nan_cols:\n",
    "        nan_count = injury_df_processed[col].isna().sum()\n",
    "        logger.warning(f\"Column '{col}' has {nan_count:,} NaN values.\")\n",
    "else:\n",
    "    logger.info(\"No NaN values found in the cleaned DataFrame.\")\n",
    "\n",
    "# Display the first 10 rows for validation\n",
    "logger.info(\"Displaying the first 10 rows of the cleaned DataFrame...\")\n",
    "print(injury_df_processed.head(10))\n",
    "\n",
    "# Calculate injuries per year per team\n",
    "logger.info(\"Extracting 'Year' from the 'Date' column...\")\n",
    "injury_df_processed['Year'] = injury_df_processed['Date'].dt.year\n",
    "logger.info(\"'Year' extraction complete.\")\n",
    "\n",
    "logger.info(\"Grouping data by 'Year' and 'Team' and counting occurrences...\")\n",
    "injury_summary_df = injury_df_processed.groupby(['Year', 'Team']).size().reset_index(name='Count')\n",
    "\n",
    "# Standardize column names to lowercase\n",
    "logger.info(\"Converting summary DataFrame column names to lowercase...\")\n",
    "injury_summary_df.columns = injury_summary_df.columns.str.lower()\n",
    "logger.info(\"Column name conversion complete.\")\n",
    "\n",
    "# Display the first 10 rows of the summary DataFrame\n",
    "logger.info(\"Displaying the first 10 rows of the grouped injury summary...\")\n",
    "print(injury_summary_df.head(10))\n",
    "\n",
    "# Save the processed data and summary data to CSV files\n",
    "output_processed_path = '../data/processed/historical/injury_data_processed.csv'\n",
    "output_summary_path = '../data/processed/historical/injuries_summary.csv'\n",
    "\n",
    "logger.info(f\"Saving cleaned injury data to {output_processed_path}...\")\n",
    "injury_df_processed.to_csv(output_processed_path, index=False)\n",
    "logger.info(f\"Cleaned injury data successfully saved to {output_processed_path}.\")\n",
    "\n",
    "logger.info(f\"Saving summarized injury data to {output_summary_path}...\")\n",
    "injury_summary_df.to_csv(output_summary_path, index=False)\n",
    "logger.info(f\"Summarized injury data successfully saved to {output_summary_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shots Data Cleaning Script\n",
    "\n",
    "This script processes and cleans NBA shot data from multiple CSV files and combines them into a single standardized dataset. It ensures consistency, resolves missing values, and prepares the data for analysis or modeling.\n",
    "\n",
    "## Key Steps:\n",
    "\n",
    "1. **Directory Validation**:\n",
    "   - Verifies the existence of the shots data directory.\n",
    "   - Searches for files matching the pattern `NBA_20[0-9][0-9]_Shots.csv`.\n",
    "   - Logs detailed information about found files or raises an error if no files are found.\n",
    "\n",
    "2. **File Loading**:\n",
    "   - Reads each file into a pandas DataFrame.\n",
    "   - Tracks and logs the number of records loaded from each file.\n",
    "   - Appends each DataFrame into a list for further processing.\n",
    "\n",
    "3. **Data Combination**:\n",
    "   - Concatenates all individual DataFrames into a single DataFrame for analysis.\n",
    "   - Logs the total number of records combined.\n",
    "\n",
    "4. **Data Cleaning**:\n",
    "   - **Standardize Team Names**:\n",
    "     - Strips whitespace, converts names to uppercase, and maps them to standardized three-letter codes.\n",
    "     - Applies transformations to `TEAM_NAME`, `HOME_TEAM`, and `AWAY_TEAM` columns.\n",
    "   - **Standardize Player Names**:\n",
    "     - Ensures consistent formatting of player names using `BaseNBACleaner`.\n",
    "   - **Numeric Column Conversion**:\n",
    "     - Converts numeric columns to appropriate types for better usability.\n",
    "   - **Handle Missing Values**:\n",
    "     - Fills missing values in `POSITION` and `POSITION_GROUP` columns with `'UNKNOWN'`.\n",
    "\n",
    "5. **Validation**:\n",
    "   - Logs the shape and column types of the DataFrame.\n",
    "   - Checks for missing values (`NaN`) across all columns and logs detailed warnings if any are found.\n",
    "\n",
    "6. **Save Processed Data**:\n",
    "   - Exports the cleaned and combined dataset to a single CSV file at `../data/processed/historical/shots.csv`.\n",
    "\n",
    "## Outputs:\n",
    "\n",
    "### Cleaned Data:\n",
    "Example of the cleaned DataFrame:\n",
    "```plaintext\n",
    "     TEAM_NAME HOME_TEAM AWAY_TEAM PLAYER_NAME POSITION POSITION_GROUP SHOT_TYPE\n",
    "0         LAL       LAL       MIA      Player1  GUARD         BACKCOURT      JUMP\n",
    "1         MIA       LAL       MIA      Player2  CENTER        FRONTCOURT      JUMP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 22:58:42 - INFO - Starting shots data cleaning process...\n",
      "2024-12-10 22:58:42 - INFO - Looking for shot files in: /Users/luke/src/github.com/lukelittle/csca5622-final-project/notebooks/../data/raw/kaggle/mexwell/nba-shots\n",
      "2024-12-10 22:58:42 - INFO - Validating the shots directory...\n",
      "2024-12-10 22:58:42 - INFO - Searching for shot files...\n",
      "2024-12-10 22:58:42 - INFO - Found 21 shot files:\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2004_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2005_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2006_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2007_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2008_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2009_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2010_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2011_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2012_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2013_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2014_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2015_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2016_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2017_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2018_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2019_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2020_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2021_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2022_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2023_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - - NBA_2024_Shots.csv\n",
      "2024-12-10 22:58:42 - INFO - Loading NBA_2004_Shots.csv...\n",
      "2024-12-10 22:58:43 - INFO - Loaded 189,803 records from NBA_2004_Shots.csv\n",
      "2024-12-10 22:58:43 - INFO - Loading NBA_2005_Shots.csv...\n",
      "2024-12-10 22:58:44 - INFO - Loaded 197,626 records from NBA_2005_Shots.csv\n",
      "2024-12-10 22:58:44 - INFO - Loading NBA_2006_Shots.csv...\n",
      "2024-12-10 22:58:44 - INFO - Loaded 194,314 records from NBA_2006_Shots.csv\n",
      "2024-12-10 22:58:44 - INFO - Loading NBA_2007_Shots.csv...\n",
      "2024-12-10 22:58:45 - INFO - Loaded 196,072 records from NBA_2007_Shots.csv\n",
      "2024-12-10 22:58:45 - INFO - Loading NBA_2008_Shots.csv...\n",
      "2024-12-10 22:58:45 - INFO - Loaded 200,501 records from NBA_2008_Shots.csv\n",
      "2024-12-10 22:58:45 - INFO - Loading NBA_2009_Shots.csv...\n",
      "2024-12-10 22:58:46 - INFO - Loaded 199,030 records from NBA_2009_Shots.csv\n",
      "2024-12-10 22:58:46 - INFO - Loading NBA_2010_Shots.csv...\n",
      "2024-12-10 22:58:47 - INFO - Loaded 200,966 records from NBA_2010_Shots.csv\n",
      "2024-12-10 22:58:47 - INFO - Loading NBA_2011_Shots.csv...\n",
      "2024-12-10 22:58:48 - INFO - Loaded 199,761 records from NBA_2011_Shots.csv\n",
      "2024-12-10 22:58:48 - INFO - Loading NBA_2012_Shots.csv...\n",
      "2024-12-10 22:58:48 - INFO - Loaded 161,205 records from NBA_2012_Shots.csv\n",
      "2024-12-10 22:58:48 - INFO - Loading NBA_2013_Shots.csv...\n",
      "2024-12-10 22:58:49 - INFO - Loaded 201,579 records from NBA_2013_Shots.csv\n",
      "2024-12-10 22:58:49 - INFO - Loading NBA_2014_Shots.csv...\n",
      "2024-12-10 22:58:49 - INFO - Loaded 204,126 records from NBA_2014_Shots.csv\n",
      "2024-12-10 22:58:49 - INFO - Loading NBA_2015_Shots.csv...\n",
      "2024-12-10 22:58:50 - INFO - Loaded 205,550 records from NBA_2015_Shots.csv\n",
      "2024-12-10 22:58:50 - INFO - Loading NBA_2016_Shots.csv...\n",
      "2024-12-10 22:58:51 - INFO - Loaded 207,893 records from NBA_2016_Shots.csv\n",
      "2024-12-10 22:58:51 - INFO - Loading NBA_2017_Shots.csv...\n",
      "2024-12-10 22:58:51 - INFO - Loaded 209,929 records from NBA_2017_Shots.csv\n",
      "2024-12-10 22:58:51 - INFO - Loading NBA_2018_Shots.csv...\n",
      "2024-12-10 22:58:52 - INFO - Loaded 211,707 records from NBA_2018_Shots.csv\n",
      "2024-12-10 22:58:52 - INFO - Loading NBA_2019_Shots.csv...\n",
      "2024-12-10 22:58:52 - INFO - Loaded 219,458 records from NBA_2019_Shots.csv\n",
      "2024-12-10 22:58:52 - INFO - Loading NBA_2020_Shots.csv...\n",
      "2024-12-10 22:58:53 - INFO - Loaded 188,116 records from NBA_2020_Shots.csv\n",
      "2024-12-10 22:58:53 - INFO - Loading NBA_2021_Shots.csv...\n",
      "2024-12-10 22:58:53 - INFO - Loaded 190,983 records from NBA_2021_Shots.csv\n",
      "2024-12-10 22:58:53 - INFO - Loading NBA_2022_Shots.csv...\n",
      "2024-12-10 22:58:54 - INFO - Loaded 216,722 records from NBA_2022_Shots.csv\n",
      "2024-12-10 22:58:54 - INFO - Loading NBA_2023_Shots.csv...\n",
      "2024-12-10 22:58:55 - INFO - Loaded 217,220 records from NBA_2023_Shots.csv\n",
      "2024-12-10 22:58:55 - INFO - Loading NBA_2024_Shots.csv...\n",
      "2024-12-10 22:58:55 - INFO - Loaded 218,701 records from NBA_2024_Shots.csv\n",
      "2024-12-10 22:58:55 - INFO - Combining all shot data into a single DataFrame...\n",
      "2024-12-10 22:58:56 - INFO - Successfully combined 4,231,262 total records.\n",
      "2024-12-10 22:58:56 - INFO - Initial data overview:\n",
      "2024-12-10 22:58:56 - INFO - Shape: (4231262, 26)\n",
      "2024-12-10 22:58:56 - INFO - Column types:\n",
      "2024-12-10 22:58:56 - INFO - SEASON_1            int64\n",
      "SEASON_2           object\n",
      "TEAM_ID             int64\n",
      "TEAM_NAME          object\n",
      "PLAYER_ID           int64\n",
      "PLAYER_NAME        object\n",
      "POSITION_GROUP     object\n",
      "POSITION           object\n",
      "GAME_DATE          object\n",
      "GAME_ID             int64\n",
      "HOME_TEAM          object\n",
      "AWAY_TEAM          object\n",
      "EVENT_TYPE         object\n",
      "SHOT_MADE            bool\n",
      "ACTION_TYPE        object\n",
      "SHOT_TYPE          object\n",
      "BASIC_ZONE         object\n",
      "ZONE_NAME          object\n",
      "ZONE_ABB           object\n",
      "ZONE_RANGE         object\n",
      "LOC_X             float64\n",
      "LOC_Y             float64\n",
      "SHOT_DISTANCE       int64\n",
      "QUARTER             int64\n",
      "MINS_LEFT           int64\n",
      "SECS_LEFT           int64\n",
      "dtype: object\n",
      "2024-12-10 22:58:56 - INFO - Standardizing team names...\n",
      "2024-12-10 22:59:11 - INFO - Team names standardized.\n",
      "2024-12-10 22:59:11 - INFO - Standardizing player names...\n",
      "2024-12-10 22:59:13 - INFO - Player names standardized.\n",
      "2024-12-10 22:59:13 - INFO - Converting numeric columns to appropriate data types...\n",
      "/Users/luke/src/github.com/lukelittle/csca5622-final-project/venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Users/luke/src/github.com/lukelittle/csca5622-final-project/venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Users/luke/src/github.com/lukelittle/csca5622-final-project/venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Users/luke/src/github.com/lukelittle/csca5622-final-project/venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Users/luke/src/github.com/lukelittle/csca5622-final-project/venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "/Users/luke/src/github.com/lukelittle/csca5622-final-project/venv/lib/python3.12/site-packages/numpy/lib/_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "2024-12-10 22:59:37 - INFO - Numeric column conversion complete.\n",
      "2024-12-10 22:59:37 - INFO - Filling missing values in 'POSITION' and 'POSITION_GROUP' columns if present...\n",
      "2024-12-10 22:59:37 - INFO - Cleaning summary:\n",
      "2024-12-10 22:59:37 - INFO - Original records: 4,231,262\n",
      "2024-12-10 22:59:37 - INFO - Cleaned records: 4,231,262\n",
      "2024-12-10 22:59:37 - INFO - Records removed during cleaning: 0\n",
      "2024-12-10 22:59:37 - INFO - Checking for NaN values in the dataset...\n",
      "2024-12-10 22:59:39 - INFO - No NaN values found in the cleaned DataFrame.\n",
      "2024-12-10 22:59:39 - INFO - Displaying the first 10 rows of the cleaned DataFrame...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEASON_1 SEASON_2     TEAM_ID TEAM_NAME  PLAYER_ID       PLAYER_NAME  \\\n",
      "0      2004  2003-04  1610612747       LAL        977       KOBE BRYANT   \n",
      "1      2004  2003-04  1610612757       POR        757  DAMON STOUDAMIRE   \n",
      "2      2004  2003-04  1610612747       LAL        977       KOBE BRYANT   \n",
      "3      2004  2003-04  1610612757       POR        757  DAMON STOUDAMIRE   \n",
      "4      2004  2003-04  1610612757       POR        757  DAMON STOUDAMIRE   \n",
      "5      2004  2003-04  1610612747       LAL       2567        BRIAN COOK   \n",
      "6      2004  2003-04  1610612757       POR        757  DAMON STOUDAMIRE   \n",
      "7      2004  2003-04  1610612747       LAL        977       KOBE BRYANT   \n",
      "8      2004  2003-04  1610612737       ATL       1544    CHRIS CRAWFORD   \n",
      "9      2004  2003-04  1610612747       LAL        977       KOBE BRYANT   \n",
      "\n",
      "  POSITION_GROUP POSITION   GAME_DATE   GAME_ID  ... BASIC_ZONE  \\\n",
      "0              G       SG  04-14-2004  20301187  ...        0.0   \n",
      "1              G       PG  04-14-2004  20301187  ...        0.0   \n",
      "2              G       SG  04-14-2004  20301187  ...        0.0   \n",
      "3              G       PG  04-14-2004  20301187  ...        0.0   \n",
      "4              G       PG  04-14-2004  20301187  ...        0.0   \n",
      "5              C        C  04-14-2004  20301187  ...        0.0   \n",
      "6              G       PG  04-14-2004  20301187  ...        0.0   \n",
      "7              G       SG  04-14-2004  20301187  ...        0.0   \n",
      "8              F       PF  04-14-2004  20301176  ...        0.0   \n",
      "9              G       SG  04-14-2004  20301187  ...        0.0   \n",
      "\n",
      "           ZONE_NAME  ZONE_ABB  ZONE_RANGE  LOC_X  LOC_Y  SHOT_DISTANCE  \\\n",
      "0   Left Side Center       0.0         0.0   20.0  21.35             25   \n",
      "1             Center       0.0         0.0   -0.0   5.25              0   \n",
      "2   Left Side Center       0.0         0.0   13.3  24.45             23   \n",
      "3          Left Side       0.0         0.0   16.4  13.95             18   \n",
      "4         Right Side       0.0         0.0  -15.8   7.85             16   \n",
      "5             Center       0.0         0.0   -0.0   5.25              0   \n",
      "6  Right Side Center       0.0         0.0  -15.8  23.15             23   \n",
      "7             Center       0.0         0.0   -1.5  29.95             24   \n",
      "8             Center       0.0         0.0   -1.0   5.75              1   \n",
      "9  Right Side Center       0.0         0.0  -14.6  16.75             18   \n",
      "\n",
      "  QUARTER  MINS_LEFT  SECS_LEFT  \n",
      "0       6          0          0  \n",
      "1       6          0          2  \n",
      "2       6          0          9  \n",
      "3       6          0         31  \n",
      "4       6          0         55  \n",
      "5       6          1         12  \n",
      "6       6          1         25  \n",
      "7       6          1         42  \n",
      "8       4          0         13  \n",
      "9       6          2         27  \n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "logger.info(\"Starting shots data cleaning process...\")\n",
    "cleaner = BaseNBACleaner()\n",
    "shots_dir = Path('../data/raw/kaggle/mexwell/nba-shots')\n",
    "\n",
    "# Log the directory being used\n",
    "logger.info(f\"Looking for shot files in: {shots_dir.absolute()}\")\n",
    "\n",
    "shots_data = []\n",
    "\n",
    "try:\n",
    "    # Validate shots directory\n",
    "    logger.info(\"Validating the shots directory...\")\n",
    "    if not shots_dir.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {shots_dir}\")\n",
    "\n",
    "    # Search for shot files\n",
    "    logger.info(\"Searching for shot files...\")\n",
    "    shots_files = sorted(shots_dir.glob('NBA_20[0-9][0-9]_Shots.csv'))\n",
    "    if not shots_files:\n",
    "        raise FileNotFoundError(f\"No shot files found in {shots_dir}\")\n",
    "\n",
    "    logger.info(f\"Found {len(shots_files)} shot files:\")\n",
    "    for file in shots_files:\n",
    "        logger.info(f\"- {file.name}\")\n",
    "\n",
    "    # Load and process each file\n",
    "    total_rows = 0\n",
    "    for file in shots_files:\n",
    "        logger.info(f\"Loading {file.name}...\")\n",
    "        df = pd.read_csv(file)\n",
    "        total_rows += len(df)\n",
    "        logger.info(f\"Loaded {len(df):,} records from {file.name}\")\n",
    "        shots_data.append(df)\n",
    "\n",
    "    # Combine all shot files into a single DataFrame\n",
    "    logger.info(\"Combining all shot data into a single DataFrame...\")\n",
    "    shots_df = pd.concat(shots_data, ignore_index=True)\n",
    "    logger.info(f\"Successfully combined {len(shots_df):,} total records.\")\n",
    "\n",
    "    # Preserve the combined raw DataFrame\n",
    "    logger.info(\"Preserving the combined raw DataFrame for reference...\")\n",
    "    shots_df_raw = shots_df.copy()\n",
    "\n",
    "    # Initial data overview\n",
    "    logger.info(\"Initial data overview:\")\n",
    "    logger.info(f\"Shape: {shots_df.shape}\")\n",
    "    logger.info(\"Column types:\")\n",
    "    logger.info(shots_df.dtypes)\n",
    "\n",
    "    # Standardize team names\n",
    "    logger.info(\"Standardizing team names...\")\n",
    "    team_columns = ['TEAM_NAME', 'HOME_TEAM', 'AWAY_TEAM']\n",
    "    for col in team_columns:\n",
    "        if col in shots_df.columns:\n",
    "            shots_df[col] = shots_df[col].str.strip().str.upper()\n",
    "    shots_df = cleaner.standardize_team_names(shots_df, team_columns)\n",
    "    logger.info(\"Team names standardized.\")\n",
    "\n",
    "    # Standardize player names\n",
    "    logger.info(\"Standardizing player names...\")\n",
    "    shots_df = cleaner.standardize_player_names(shots_df, 'PLAYER_NAME')\n",
    "    logger.info(\"Player names standardized.\")\n",
    "\n",
    "    # Convert numeric columns to appropriate types\n",
    "    logger.info(\"Converting numeric columns to appropriate data types...\")\n",
    "    shots_df = cleaner.handle_numeric_columns(shots_df)\n",
    "    logger.info(\"Numeric column conversion complete.\")\n",
    "\n",
    "    # Fill missing values in specific columns\n",
    "    logger.info(\"Filling missing values in 'POSITION' and 'POSITION_GROUP' columns if present...\")\n",
    "    if 'POSITION' in shots_df.columns:\n",
    "        shots_df['POSITION'] = shots_df['POSITION'].fillna('UNKNOWN')\n",
    "    if 'POSITION_GROUP' in shots_df.columns:\n",
    "        shots_df['POSITION_GROUP'] = shots_df['POSITION_GROUP'].fillna('UNKNOWN')\n",
    "\n",
    "    # Cleaning summary\n",
    "    logger.info(\"Cleaning summary:\")\n",
    "    logger.info(f\"Original records: {total_rows:,}\")\n",
    "    logger.info(f\"Cleaned records: {len(shots_df):,}\")\n",
    "    logger.info(f\"Records removed during cleaning: {total_rows - len(shots_df):,}\")\n",
    "\n",
    "    # Check for NaN values\n",
    "    logger.info(\"Checking for NaN values in the dataset...\")\n",
    "    nan_cols = shots_df.columns[shots_df.isna().any()].tolist()\n",
    "    if nan_cols:\n",
    "        logger.warning(f\"Found NaN values in the following columns: {nan_cols}\")\n",
    "        for col in nan_cols:\n",
    "            nan_count = shots_df[col].isna().sum()\n",
    "            logger.warning(f\"Column '{col}' has {nan_count:,} NaN values.\")\n",
    "    else:\n",
    "        logger.info(\"No NaN values found in the cleaned DataFrame.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error processing shots data: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Display the first 10 rows of the cleaned DataFrame\n",
    "logger.info(\"Displaying the first 10 rows of the cleaned DataFrame...\")\n",
    "print(shots_df.head(10))\n",
    "\n",
    "# Save the raw and cleaned DataFrames to separate CSV files\n",
    "raw_output_path = '../data/processed/historical/shots_raw.csv'\n",
    "cleaned_output_path = '../data/processed/historical/shots_cleaned.csv'\n",
    "\n",
    "logger.info(f\"Saving combined raw shots data to {raw_output_path}...\")\n",
    "shots_df_raw.to_csv(raw_output_path, index=False)\n",
    "logger.info(f\"Raw shots data successfully saved to {raw_output_path}.\")\n",
    "\n",
    "logger.info(f\"Saving cleaned shots data to {cleaned_output_path}...\")\n",
    "shots_df.to_csv(cleaned_output_path, index=False)\n",
    "logger.info(f\"Cleaned shots data successfully saved to {cleaned_output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
