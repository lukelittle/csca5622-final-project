{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Playoff Predictor - Data Cleaning\n",
    "\n",
    "This notebook focuses on cleaning and preprocessing the raw NBA data from Kaggle sources. We'll prepare the data for feature engineering by standardizing formats, handling missing values, and ensuring data quality across different sources.\n",
    "\n",
    "## Data Sources and Cleaning Goals\n",
    "\n",
    "1. **NBA/ABA/BAA Stats (sumitrodatta)**\n",
    "   - Player Season Info: Contains individual player statistics per season\n",
    "     - Cleaning focuses on standardizing team names, filtering for NBA-only data\n",
    "     - Adding conference information for each team\n",
    "     - Handling missing values\n",
    "   - Team Stats Per Game: Contains team-level performance metrics\n",
    "     - Cleaning involves normalizing team names\n",
    "     - Adding conference mappings\n",
    "     - Ensuring consistent statistical calculations\n",
    "\n",
    "2. **NBA Injury Stats (loganlauton)**\n",
    "   - Contains historical injury data from 1951-2023\n",
    "   - Cleaning involves:\n",
    "     - Standardizing team names\n",
    "     - Converting dates to consistent format\n",
    "     - Adding conference information\n",
    "     - Creating yearly injury summaries per team\n",
    "     - Removing duplicate entries\n",
    "\n",
    "## Conference Mapping\n",
    "\n",
    "Each dataset is enhanced with conference information to support playoff prediction:\n",
    "- Teams are mapped to either 'EAST' or 'WEST' conference\n",
    "- Historical conference alignments are considered\n",
    "- Conference information is crucial for playoff qualification rules\n",
    "  - Pre-2020: Top 8 teams per conference\n",
    "  - 2020 onward: Top 6 automatic + Play-in tournament (7-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.cleaners.nba_data_cleaner import NBACleaner\n",
    "from src.data.utils import setup_logging\n",
    "\n",
    "logger = setup_logging()\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "cleaner = NBACleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean NBA/ABA/BAA Stats\n",
    "\n",
    "Process data from sumitrodatta's dataset.\n",
    "\n",
    "The cleaning process ensures consistent formatting, adds conference information, and removes any anomalies that could affect our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Season Data Cleaning Script\n",
    "\n",
    "This script is designed to clean and standardize NBA player season data for analysis. It performs the following operations:\n",
    "\n",
    "1. **Load Data**: Reads the raw player season data from a CSV file.\n",
    "2. **Filter by Season**: Removes records from seasons prior to 2004 to focus on recent data.\n",
    "3. **Drop Unnecessary Columns**: Eliminates irrelevant columns such as `player_id`, `seas_id`, `birth_year`, `pos`, and `lg`.\n",
    "4. **Standardize Names**:\n",
    "   - Player names are standardized using `NBACleaner`\n",
    "   - Team names are converted to uppercase and standardized\n",
    "5. **Add Conference Information**:\n",
    "   - Maps teams to their respective conferences\n",
    "   - Handles historical conference changes\n",
    "6. **Convert Columns**:\n",
    "   - The `age` column is converted to an integer type\n",
    "   - Other numeric columns are standardized as needed\n",
    "7. **Validate Data**:\n",
    "   - Checks for missing values\n",
    "   - Verifies conference mappings\n",
    "\n",
    "### Output\n",
    "- A cleaned dataset is saved as `../data/processed/player_season.csv`\n",
    "- Includes player statistics with team and conference information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean player season info data\n",
    "logger.info(\"Loading player season info data...\")\n",
    "ps_df_raw = pd.read_csv('../data/raw/kaggle/sumitrodatta/nba-aba-baa-stats/Player Season Info.csv')\n",
    "logger.info(f\"Initial player season info records: {len(ps_df_raw):,}\")\n",
    "\n",
    "# Make a copy of the raw data for processing\n",
    "ps_df_processed = ps_df_raw.copy()\n",
    "\n",
    "# Filter out data before 2004\n",
    "logger.info(\"Filtering out records before 2004...\")\n",
    "ps_df_processed = ps_df_processed[ps_df_processed['season'] >= 2004]\n",
    "logger.info(f\"Records after filtering pre-2004 data: {len(ps_df_processed):,}\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['player_id', 'seas_id', 'birth_year', 'pos', 'lg']\n",
    "logger.info(f\"Dropping unnecessary columns: {columns_to_drop}...\")\n",
    "ps_df_processed.drop(columns=columns_to_drop, inplace=True)\n",
    "logger.info(\"Unnecessary columns dropped.\")\n",
    "\n",
    "# Standardize player names\n",
    "logger.info(\"Standardizing player names...\")\n",
    "ps_df_processed = cleaner.standardize_player_names(ps_df_processed)\n",
    "logger.info(\"Player name standardization complete.\")\n",
    "\n",
    "# Standardize team names\n",
    "logger.info(\"Standardizing team names: converting to uppercase and stripping whitespace...\")\n",
    "ps_df_processed['tm'] = ps_df_processed['tm'].str.strip().str.upper()\n",
    "ps_df_processed = cleaner.standardize_team_names(ps_df_processed, ['tm'])\n",
    "logger.info(\"Team name standardization complete.\")\n",
    "\n",
    "# Rename 'tm' column to 'team'\n",
    "logger.info(\"Renaming 'tm' column to 'team'...\")\n",
    "ps_df_processed.rename(columns={'tm': 'team'}, inplace=True)\n",
    "logger.info(\"Column 'tm' successfully renamed to 'team'.\")\n",
    "\n",
    "# Convert 'age' column to integer type\n",
    "logger.info(\"Converting 'age' column to integer type...\")\n",
    "ps_df_processed['age'] = pd.to_numeric(ps_df_processed['age'], errors='coerce').fillna(0).astype(int)\n",
    "logger.info(\"'age' column conversion to integer complete.\")\n",
    "\n",
    "# Add conference mappings\n",
    "ps_df_processed = cleaner.add_conference_mappings(ps_df_processed, name_col='team')\n",
    "\n",
    "unknown_teams = ps_df_processed[ps_df_processed['conference'] == 'Unknown']['team'].unique()\n",
    "if len(unknown_teams) > 0:\n",
    "    logger.warning(f\"Found teams with unknown conference: {unknown_teams}\")\n",
    "else:\n",
    "    logger.info(\"All teams successfully mapped to conferences\")\n",
    "\n",
    "# Check for NaN values\n",
    "logger.info(\"Checking for NaN values in the dataset...\")\n",
    "nan_cols = ps_df_processed.columns[ps_df_processed.isna().any()].tolist()\n",
    "if nan_cols:\n",
    "    logger.warning(f\"Found NaN values in the following columns: {nan_cols}\")\n",
    "    for col in nan_cols:\n",
    "        nan_count = ps_df_processed[col].isna().sum()\n",
    "        logger.warning(f\"Column '{col}' has {nan_count:,} NaN values.\")\n",
    "else:\n",
    "    logger.info(\"No NaN values found in the cleaned DataFrame.\")\n",
    "\n",
    "# Display sample and save\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "print(ps_df_processed.head())\n",
    "\n",
    "output_path = '../data/processed/player_season.csv'\n",
    "ps_df_processed.to_csv(output_path, index=False)\n",
    "logger.info(f\"Cleaned data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Player Season Data\n",
    "dataset_name = \"Player Season Data\"\n",
    "raw_count = len(ps_df_raw)  \n",
    "processed_count = len(ps_df_processed) \n",
    "\n",
    "# Data for plotting\n",
    "stages = ['Raw Data (Combined)', 'Processed Data']\n",
    "counts = [raw_count, processed_count]\n",
    "colors = ['steelblue', 'orange']\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Create horizontal bars\n",
    "bars = ax.barh(stages, counts, color=colors)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height() / 2,\n",
    "            f'{int(width):,}',\n",
    "            ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_title(f'Data Cleaning Funnel: {dataset_name}', pad=20)\n",
    "ax.set_xlabel('Number of Records')\n",
    "\n",
    "# Remove spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add padding\n",
    "ax.set_xlim(0, max(counts) * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Statistics Data Cleaning Script\n",
    "\n",
    "This script processes and cleans NBA team statistics data for analysis. It performs the following steps:\n",
    "\n",
    "1. **Load Data**: Reads the raw team statistics data.\n",
    "2. **Filter by Season**: Removes records prior to 2004.\n",
    "3. **Remove League Averages**: Excludes league average entries.\n",
    "4. **Standardize Team Names**:\n",
    "   - Converts to uppercase\n",
    "   - Maps to standardized codes\n",
    "5. **Add Conference Information**:\n",
    "   - Maps teams to conferences\n",
    "   - Validates conference assignments\n",
    "6. **Convert Data Types**:\n",
    "   - Handles numeric columns\n",
    "   - Converts percentages to decimals\n",
    "7. **Validate Data**:\n",
    "   - Checks for missing values\n",
    "   - Verifies data consistency\n",
    "\n",
    "### Output\n",
    "- Cleaned dataset saved as `../data/processed/team_stats.csv`\n",
    "- Includes team statistics with conference information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean team stats data\n",
    "logger.info(\"Loading team stats data...\")\n",
    "ts_df_raw = pd.read_csv('../data/raw/kaggle/sumitrodatta/nba-aba-baa-stats/Team Stats Per Game.csv')\n",
    "logger.info(f\"Initial team stats records: {len(ts_df_raw):,}\")\n",
    "\n",
    "# Make a copy of the raw data for processing\n",
    "ts_df_processed = ts_df_raw.copy()\n",
    "\n",
    "# Filter out data before 2004\n",
    "logger.info(\"Filtering out records before 2004...\")\n",
    "ts_df_processed = ts_df_processed[ts_df_processed['season'] >= 2004]\n",
    "logger.info(f\"Records after filtering pre-2004 data: {len(ts_df_processed):,}\")\n",
    "\n",
    "# Remove League Average entries\n",
    "logger.info(\"Removing 'League Average' entries from the data...\")\n",
    "ts_df_processed = ts_df_processed[~ts_df_processed['team'].str.contains('League Average', case=False, na=False)]\n",
    "logger.info(f\"Records after removing 'League Average' entries: {len(ts_df_processed):,}\")\n",
    "\n",
    "# Standardize team names\n",
    "logger.info(\"Standardizing team names...\")\n",
    "ts_df_processed['team'] = ts_df_processed['team'].str.strip().str.upper()\n",
    "ts_df_processed = cleaner.standardize_team_names(ts_df_processed, ['team'])\n",
    "logger.info(\"Team name standardization complete.\")\n",
    "\n",
    "# Convert percentage strings to decimals\n",
    "logger.info(\"Converting percentage strings to decimal values...\")\n",
    "ts_df_processed = cleaner.convert_percentages(ts_df_processed)\n",
    "logger.info(\"Percentage conversion complete.\")\n",
    "\n",
    "# Add conference mappings\n",
    "ts_df_processed = cleaner.add_conference_mappings(ts_df_processed, name_col='team')\n",
    "\n",
    "unknown_teams = ts_df_processed[ts_df_processed['conference'] == 'Unknown']['team'].unique()\n",
    "if len(unknown_teams) > 0:\n",
    "    logger.warning(f\"Found teams with unknown conference: {unknown_teams}\")\n",
    "else:\n",
    "    logger.info(\"All teams successfully mapped to conferences\")\n",
    "\n",
    "# Check for NaN values\n",
    "logger.info(\"Checking for NaN values in the dataset...\")\n",
    "nan_cols = ts_df_processed.columns[ts_df_processed.isna().any()].tolist()\n",
    "if nan_cols:\n",
    "    logger.warning(f\"Found NaN values in the following columns: {nan_cols}\")\n",
    "    for col in nan_cols:\n",
    "        nan_count = ts_df_processed[col].isna().sum()\n",
    "        logger.warning(f\"Column '{col}' has {nan_count:,} NaN values.\")\n",
    "else:\n",
    "    logger.info(\"No NaN values found in the cleaned DataFrame.\")\n",
    "\n",
    "# Display sample and save\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "print(ts_df_processed.head())\n",
    "\n",
    "output_path = '../data/processed/team_stats.csv'\n",
    "ts_df_processed.to_csv(output_path, index=False)\n",
    "logger.info(f\"Cleaned data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Team Statistics data\n",
    "dataset_name = \"Team Statistics data\"\n",
    "raw_count = len(ts_df_raw)\n",
    "processed_count = len(ts_df_processed)\n",
    "\n",
    "# Data for plotting\n",
    "stages = ['Raw Data (Combined)', 'Processed Data']\n",
    "counts = [raw_count, processed_count]\n",
    "colors = ['steelblue', 'orange']\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Create horizontal bars\n",
    "bars = ax.barh(stages, counts, color=colors)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height() / 2,\n",
    "            f'{int(width):,}',\n",
    "            ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_title(f'Data Cleaning Funnel: {dataset_name}', pad=20)\n",
    "ax.set_xlabel('Number of Records')\n",
    "\n",
    "# Remove spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add padding\n",
    "ax.set_xlim(0, max(counts) * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injury Data Cleaning and Summary Script\n",
    "\n",
    "This script processes NBA player injury data to create team-level injury summaries. It performs the following steps:\n",
    "\n",
    "1. **Load Data**: Reads raw injury data.\n",
    "2. **Clean Dates**: Converts to datetime format.\n",
    "3. **Filter Data**: Removes pre-2004 records.\n",
    "4. **Standardize Teams**:\n",
    "   - Converts team names to standard format\n",
    "   - Maps historical team names\n",
    "5. **Add Conference Information**:\n",
    "   - Maps teams to conferences\n",
    "   - Validates conference assignments\n",
    "6. **Create Summary**:\n",
    "   - Groups by year and team\n",
    "   - Counts injuries per team-season\n",
    "\n",
    "### Outputs\n",
    "- Injury summary: `../data/processed/injuries_summary.csv`\n",
    "  - Year, team, conference, injury count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean injury data\n",
    "logger.info(\"Loading player injury data...\")\n",
    "injury_df_raw = pd.read_csv('../data/raw/kaggle/loganlauton/nba-injury-stats-1951-2023/NBA Player Injury Stats(1951 - 2023).csv')\n",
    "logger.info(f\"Initial player injury records: {len(injury_df_raw):,}\")\n",
    "\n",
    "# Make a copy of the raw data for processing\n",
    "injury_df_processed = injury_df_raw.copy()\n",
    "\n",
    "# Convert dates to datetime\n",
    "logger.info(\"Converting 'Date' column to datetime format...\")\n",
    "injury_df_processed = cleaner.handle_dates(injury_df_processed, ['Date'])\n",
    "logger.info(\"Date conversion complete.\")\n",
    "\n",
    "# Filter out data before 2004\n",
    "logger.info(\"Filtering out records before 2004...\")\n",
    "injury_df_processed = injury_df_processed[injury_df_processed['Date'] >= '2004-01-01']\n",
    "logger.info(f\"Records after filtering pre-2004 data: {len(injury_df_processed):,}\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['Unnamed: 0', 'Acquired', 'Relinquished', 'Notes']\n",
    "logger.info(f\"Dropping unnecessary columns: {columns_to_drop}...\")\n",
    "injury_df_processed.drop(columns=columns_to_drop, inplace=True)\n",
    "logger.info(\"Unnecessary columns dropped.\")\n",
    "\n",
    "# Standardize team names\n",
    "logger.info(\"Standardizing team names...\")\n",
    "injury_df_processed['Team'] = injury_df_processed['Team'].str.strip().str.upper()\n",
    "injury_df_processed = cleaner.standardize_team_names(injury_df_processed, ['Team'])\n",
    "logger.info(\"Team name standardization complete.\")\n",
    "\n",
    "# Extract year and create summary\n",
    "logger.info(\"Creating injury summary...\")\n",
    "injury_df_processed['Year'] = injury_df_processed['Date'].dt.year\n",
    "injury_summary_df = injury_df_processed.groupby(['Year', 'Team']).size().reset_index(name='Count')\n",
    "\n",
    "# Add conference mappings\n",
    "injury_summary_df = cleaner.add_conference_mappings(injury_summary_df, name_col='Team')\n",
    "\n",
    "unknown_teams = injury_summary_df[injury_summary_df['conference'] == 'Unknown']['Team'].unique()\n",
    "if len(unknown_teams) > 0:\n",
    "    logger.warning(f\"Found teams with unknown conference: {unknown_teams}\")\n",
    "else:\n",
    "    logger.info(\"All teams successfully mapped to conferences\")\n",
    "\n",
    "# Standardize column names\n",
    "logger.info(\"Converting column names to lowercase...\")\n",
    "injury_summary_df.columns = injury_summary_df.columns.str.lower()\n",
    "\n",
    "# Display sample and save\n",
    "print(\"\\nSample of injury summary:\")\n",
    "print(injury_summary_df.head())\n",
    "\n",
    "output_path = '../data/processed/injuries_summary.csv'\n",
    "injury_summary_df.to_csv(output_path, index=False)\n",
    "logger.info(f\"Injury summary saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Player Injury Data\n",
    "dataset_name = \"Player Injury Data\"\n",
    "raw_count = len(injury_df_raw)  \n",
    "processed_count = len(injury_df_processed) \n",
    "\n",
    "# Data for plotting\n",
    "stages = ['Raw Data (Combined)', 'Processed Data']\n",
    "counts = [raw_count, processed_count]\n",
    "colors = ['steelblue', 'orange']\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Create horizontal bars\n",
    "bars = ax.barh(stages, counts, color=colors)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height() / 2,\n",
    "            f'{int(width):,}',\n",
    "            ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_title(f'Data Cleaning Funnel: {dataset_name}', pad=20)\n",
    "ax.set_xlabel('Number of Records')\n",
    "\n",
    "# Remove spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add padding\n",
    "ax.set_xlim(0, max(counts) * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
